{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nExperiment Scheduler using HPO Algorithms\n=========================================\n\nIn previous course, we learn how to define search spaces, construct a :class:`autotorch.searcher.RandomSearcher`, run a single trial using searcher suggested configurations.\n\nIn this course, we will construct a AutoTorch experiment scheduler and go through the overall system workflow using a toy example.\n\nAutoTorch System Implementatin Logic\n------------------------------------\n\n![](https://raw.githubusercontent.com/zhanghang1989/AutoGluonWebdata/master/doc/api/autogluon_system.png)\n\n    :width: 500px\n    :alt: AutoTorch System Overview\n    :align: center\n\nImportant components of the AutoTorch system include the Searcher, Scheduler and Resource Manager:\n\n- The Searcher suggests hyperparameter configurations for the next training job.\n- The Scheduler runs the training job when computation resources become available.\n\nIn this tutorial, we illustrate how various search algorithms work and\ncompare their performance via toy experiments.\n\nFIFO Scheduling vs. Early Stopping\n----------------------------------\n\nIn this section, we compare the different behaviors of a sequential First In, First Out (FIFO) scheduler using :class:`autotorch.scheduler.FIFOScheduler` vs. a preemptive scheduling algorithm\n:class:`autotorch.scheduler.HyperbandScheduler` that early-terminates certain training jobs that do not appear promising during their early stages.\n\nCreate a Dummy Training Function\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport autotorch as at\n\n@at.args(\n    lr=at.Real(1e-3, 1e-2, log=True),\n    wd=at.Real(1e-3, 1e-2))\ndef train_fn(args, reporter):\n    for e in range(10):\n        dummy_accuracy = 1 - np.power(1.8, -np.random.uniform(e, 2*e))\n        reporter(epoch=e, accuracy=dummy_accuracy, lr=args.lr, wd=args.wd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- FIFO Scheduler\n\nThis scheduler runs training trials in order. When there are more resources available than required for a single training job, multiple training jobs may be run in parallel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scheduler = at.scheduler.FIFOScheduler(train_fn,\n                                       resource={'num_cpus': 2, 'num_gpus': 0},\n                                       num_trials=20,\n                                       reward_attr='accuracy',\n                                       time_attr='epoch')\nscheduler.run()\nscheduler.join_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scheduler.get_training_curves(plot=True, use_legend=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Hyperband Scheduler\n\nThe Hyperband Scheduler terminates training trials that don't appear promising during the early stages to free up compute resources for more promising hyperparameter configurations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scheduler = at.scheduler.HyperbandScheduler(train_fn,\n                                            resource={'num_cpus': 2, 'num_gpus': 0},\n                                            num_trials=20,\n                                            reward_attr='accuracy',\n                                            time_attr='epoch',\n                                            grace_period=1)\nscheduler.run()\nscheduler.join_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scheduler.get_training_curves(plot=True, use_legend=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}